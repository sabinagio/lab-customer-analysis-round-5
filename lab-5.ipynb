{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. X-y split.\n",
    "\n",
    "In order to do the X-y split, we need to figure out the inputs and outputs of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Find more information about the dataset\n",
    "df = pd.read_csv('files_for_lab/csv_files/marketing_customer_analysis.csv')\n",
    "print(df.info())\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "# Run the transformations from the previous lab\n",
    "\n",
    "# 1. Standardize column names\n",
    "df.rename(columns = {'EmploymentStatus': 'Employment Status'}, inplace = True)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# 2. Remove columns that are highly correlated to each other\n",
    "df.drop(['policy', 'vehicle size'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume that the `total claim amount` is the output we're looking to predict, as for an insurance policy company it would be relevant to know which customer type is more likely to make claims - so that they can perhaps change the insurance policy pricing for customers that would be considered \"high-risk\", i.e. more likely to make claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(df['total claim amount'])\n",
    "X = df.drop('total claim amount', axis=1)\n",
    "\n",
    "# Check that the operations ran correctly\n",
    "print(y.columns)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Normalize (numerical).\n",
    "\n",
    "We need to separate the numerical columns in X from the categorical columns so we can normalize the data at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include=np.number)\n",
    "\n",
    "# Check that we have selected the correct data\n",
    "print(X_num.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can normalize the data using `MinMaxScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the minimum and maximum for each column of the dataframe:\n",
    "transformer = MinMaxScaler().fit(X_num) \n",
    "\n",
    "# Find out what the transformer is:\n",
    "print(type(transformer))\n",
    "\n",
    "# Show the maximum across all columns (mainly to see what the info in the transformer):\n",
    "print(transformer.data_max_)\n",
    "\n",
    "# Normalize the data (or transform):\n",
    "x_minmax = transformer.transform(X_num)\n",
    "print(type(x_minmax))\n",
    "print(x_minmax.shape)\n",
    "\n",
    "# Transform the numpy array into the normalized dataframe \n",
    "X_num_norm = pd.DataFrame(x_minmax, columns=X_num.columns)\n",
    "print(X_num_norm.head())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
